{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "lil = pickle.load(open('lil.pkl', 'rb'))\n",
    "csr  = csr_matrix(lil).astype(np.float32)\n",
    "target = pd.read_csv('target.csv')['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4647, 69219)\n",
      "987641\n"
     ]
    }
   ],
   "source": [
    "print(lil.shape)\n",
    "print(lil.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttrain's rmse: 37.2401\tvalid's rmse: 29.7573\n",
      "[100]\ttrain's rmse: 33.8889\tvalid's rmse: 28.8403\n",
      "[150]\ttrain's rmse: 31.407\tvalid's rmse: 28.7056\n",
      "[200]\ttrain's rmse: 29.4402\tvalid's rmse: 28.7246\n",
      "Early stopping, best iteration is:\n",
      "[152]\ttrain's rmse: 31.3311\tvalid's rmse: 28.6909\n",
      "\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttrain's rmse: 36.4892\tvalid's rmse: 33.2012\n",
      "[100]\ttrain's rmse: 32.879\tvalid's rmse: 32.57\n",
      "[150]\ttrain's rmse: 30.3775\tvalid's rmse: 32.5202\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttrain's rmse: 30.9931\tvalid's rmse: 32.5135\n",
      "\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttrain's rmse: 36.0117\tvalid's rmse: 36.0767\n",
      "[100]\ttrain's rmse: 32.8159\tvalid's rmse: 34.3324\n",
      "[150]\ttrain's rmse: 30.4663\tvalid's rmse: 33.8078\n",
      "[200]\ttrain's rmse: 28.615\tvalid's rmse: 33.4169\n",
      "[250]\ttrain's rmse: 27.0214\tvalid's rmse: 33.1433\n",
      "[300]\ttrain's rmse: 25.6672\tvalid's rmse: 33.0499\n",
      "[350]\ttrain's rmse: 24.4905\tvalid's rmse: 33.0117\n",
      "Early stopping, best iteration is:\n",
      "[317]\ttrain's rmse: 25.2644\tvalid's rmse: 32.957\n",
      "\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttrain's rmse: 33.4594\tvalid's rmse: 46.9373\n",
      "[100]\ttrain's rmse: 29.9438\tvalid's rmse: 45.316\n",
      "[150]\ttrain's rmse: 27.6234\tvalid's rmse: 44.6965\n",
      "[200]\ttrain's rmse: 25.6838\tvalid's rmse: 44.3242\n",
      "[250]\ttrain's rmse: 24.11\tvalid's rmse: 44.2796\n",
      "[300]\ttrain's rmse: 22.7652\tvalid's rmse: 44.3507\n",
      "Early stopping, best iteration is:\n",
      "[258]\ttrain's rmse: 23.9121\tvalid's rmse: 44.2456\n",
      "\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttrain's rmse: 34.296\tvalid's rmse: 43.8431\n",
      "[100]\ttrain's rmse: 30.9719\tvalid's rmse: 42.3482\n",
      "[150]\ttrain's rmse: 28.6375\tvalid's rmse: 41.6833\n",
      "[200]\ttrain's rmse: 26.7722\tvalid's rmse: 41.5604\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttrain's rmse: 27.5734\tvalid's rmse: 41.5273\n",
      "LGB OOF RMSE: 36.46314938896055\n",
      "LGB OOF MAE: 4.390465478809027\n",
      "Modeling Stage\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import lightgbm as lgb\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "def get_oof(clf, x_train, y, x_test):\n",
    "    train_h, train_w = x_train.shape\n",
    "    test_h, test_w = x_test.shape\n",
    "    NFOLDS=5\n",
    "    SEED=71\n",
    "    kf = KFold(train_h, n_folds=NFOLDS, shuffle=True, random_state=SEED)\n",
    "    oof_train = np.zeros((train_h,))\n",
    "    oof_test = np.zeros((test_h,))\n",
    "    oof_test_skf = np.empty((NFOLDS, test_h))\n",
    "    lgbm_params =  {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        # 'max_depth': 15,\n",
    "        'num_leaves': 100,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.75,\n",
    "        'bagging_freq': 4,\n",
    "        'learning_rate': 0.016,\n",
    "        #'max_bin':1023,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        print('\\nFold {}'.format(i))\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y[train_index]\n",
    "        y_te = y[test_index]\n",
    "        x_te = x_train[test_index]\n",
    "        lgtrain = lgb.Dataset(x_tr, y_tr)\n",
    "                    #feature_name=x_train.columns.tolist())\n",
    "        lgvalid = lgb.Dataset(x_te, y_te)\n",
    "                    #feature_name=x_train.columns.tolist())\n",
    "                    #categorical_feature = categorical)\n",
    "        lgb_clf = lgb.train(\n",
    "            lgbm_params,\n",
    "            lgtrain,\n",
    "            num_boost_round=2000,\n",
    "            valid_sets=[lgtrain, lgvalid],\n",
    "            valid_names=['train','valid'],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=50\n",
    "        )\n",
    "        pickle.dump(lgb_clf, open(f'models/{i:09d}.pkl', 'wb'))\n",
    "        oof_train[test_index] = lgb_clf.predict(x_te)\n",
    "        oof_test_skf[i, :]    = lgb_clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train, oof_test\n",
    "#Ridge oof method from Faron's kernel\n",
    "#I was using this to analyze my vectorization, but figured it would be interesting to add the results back into the dataset\n",
    "#It doesn't really add much to the score, but it does help lightgbm converge faster\n",
    "oof_train, oof_test = get_oof(None, csr, target, csr)\n",
    "rms = sqrt(mean_squared_error(target, oof_train))\n",
    "print('LGB OOF RMSE: {}'.format(rms))\n",
    "mae = sqrt(mean_absolute_error(target, oof_train))\n",
    "print('LGB OOF MAE: {}'.format(mae))\n",
    "print(\"Modeling Stage\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
